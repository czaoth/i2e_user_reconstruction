\section{Stand der Forschung}
\label{sec:forschung}

Wie bereits einleitend erwähnt, hat die Anwendung von MR Technologien in der Konstruktionsdomäne eine lange Tradition. Betrachtet man die Lösungen, die in \cite{Rankohi:2013} besprochen werden, lässt sich zusammenfassen, dass keine der bestehenden Applikationen, verteilte Kollaboration in Entwurf oder Konstruktion in dem hier vorgestellten Umfang unterstützt. 

Hingegen: Instruments for Collective Design in a Professional Context: Digital Format or New Processes ? ACHI 2015

A number of 3D MR construction environments have been developed in recent years. Salim \cite{Salim:2014:TUS:2664323.2664346} uses tangible building blocks and physical gestures to construct virtual urban landscapes on a 3D simulation table. Though  already employing marker-less object tracking and object reconstruction, the solution is designed as a stationary, single user application. As opposed to \cite{Salim:2014:TUS:2664323.2664346}, we employ marker-based object tracking with visible markers like in \cite{garrido2014automatic} or \cite{fiala2010designing} for efficient identification and more reliable 3D pose detection. Though different proposals exist to estimate the object pose from non-coplanar feature points like in \cite{qin2008new} and \cite{DeMenthon95model-basedobject}, we decided to implement an algorithm using coplanar feature points as described in \cite{oberkampf1996iterative} allowing for object pose calculation with only one recognized marker. 

MirageTable \cite{Benko:2012:MFI:2207676.2207704} is an environment to combine the virtual and real world in a consistent virtual scene. It supports the construction task as combination of real and virtual objects and collaboration of users on a common model supplying 3D representations of the participants in the scene. It also allows for physically-realistic freehand gestures to manipulate virtual objects. Moreover, marker-less object tracking, object reconstruction and replicating real objects into virtual ones are contained. Though very close to our proposal, they follow a stationary approach with a stereoscopic projection. Here movement, fast on-line reconstruction of humans and dynamically changing perspectives are not considered. Since we propose a mobile setup, where participants are allowed to move around in the scene, there is a need for complete 3D models of all remote participants. Due to constant changes in perspectives, the reconstruction task needs to be performed in near real-time. Though Tong et  al. \cite{tong2012scanning} have shown the feasibility of using multiple consumer-grade depth cameras for reconstruction, their approach is too slow to create real-time dynamic meshes. As opposed to Alexiadis et al. \cite{alexiadis2013real}, whose real-time reconstructed 3D models contain a high number of vertices, which is unsuitable for later streaming, in our solution, the data volume of the reconstruction process can be adapted in an early stage. This allows us to balance performance with mesh quality. As far as gestural interaction is concerned our work joins physical and interpreted gestures to achieve consistent device free interaction. For physical gestures we adapt the work of Song et al. \cite{song2008vision} and Hilliges et al. \cite{hilliges2012holodesk}. For interpreted gestures we extend the template-based approach of Kristensson et al. \cite{Kristensson:2012:CRO:2166966.2166983} for 2D gestures to 3D spatial interaction. 

MixFab \cite{Weichel:2014:MME:2611222.2557090} is a MR environment for gesture-based construction of 3D objects in a stationary setting with a see-through display. Real objects are scanned by means of a depth sensor and can be combined with virtual ones. Manipulations range from joining real and virtual objects to deforming virtual by means of real objects. Having focus on mixed construction manipulations and gestures, MixFab does not support collaborative tasks, nor does it provide a mobile solution. 

Mockup Builder \cite{DeArauJo:2013:SST:2464168.2464286} is a semi-immersive environment for freehand construction of 3D virtual models on a stereoscopic multi-touch table. The focus is on appropriate, convenient hand-gestures and thus, an excellent foundation for further development of our gestural interface.

Interactions within Distributed Mixed Reality Collaborative Environments. \cite{pena-rios2014}